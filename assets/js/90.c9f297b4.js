(window.webpackJsonp=window.webpackJsonp||[]).push([[90],{591:function(e,t,a){"use strict";a.r(t);var i=a(6),r=Object(i.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})]),e._v(" "),a("h2",{attrs:{id:"deepfm提出的动机是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deepfm提出的动机是什么"}},[e._v("#")]),e._v(" DeepFM提出的动机是什么？")]),e._v(" "),a("p",[e._v("目前大部分的CTR预估模型“are biased to low- or high- order feature interaction”，例如FNN、PNN等NN模型专注于隐式的高阶特征相关性，而LR、FM等则专注于显式对得到低阶特征相关性，Google在2016年提出的Wide&Deep模型同时考虑了两者，但Wide部分需要人工参与特征工程。")]),e._v(" "),a("p",[e._v("DeepFM的动机非常直观，既希望考虑高/低阶的feature interaction，又想省去额外的特征工程。使用FM取代Wide的LR部分是一个可行的做法，当然这里LR可以基于先验构造更高阶的组合特征，而FM只考虑二阶。")]),e._v(" "),a("h2",{attrs:{id:"deepfm中fm层与nn层是共享特征embedding的好处是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deepfm中fm层与nn层是共享特征embedding的好处是什么"}},[e._v("#")]),e._v(" DeepFM中FM层与NN层是共享特征Embedding的好处是什么？")]),e._v(" "),a("ul",[a("li",[a("p",[e._v("1）降低模型复杂度，提升模型性能；")])]),e._v(" "),a("li",[a("p",[e._v("2）在embedding的学习中同时接收与来自“low & high order interaction”部分的反馈，从而学到更好的特征表示。")])])]),e._v(" "),a("h2",{attrs:{id:"deepfm相较于wide-deep有什么改进-为什么这么改进"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deepfm相较于wide-deep有什么改进-为什么这么改进"}},[e._v("#")]),e._v(" DeepFM相较于Wide&Deep有什么改进？为什么这么改进？")]),e._v(" "),a("ol",[a("li",[a("p",[e._v("DeepFM对Wide&Deep模型的改进之处在于用FM替换了原来的Wide部分,加强了浅层网络部分特征组合的能力。")])]),e._v(" "),a("li",[a("p",[e._v("DeepFM中的FM层和隐藏层共享输入。这种共享输入使得DeepFM可以同时从原始特征中学习低阶特征交互和高阶特征交互,完全不需要执行特征工程。")])])]),e._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/007S8ZIlly1ghseamfau3j30k80a7goq.jpg",alt:""}})]),e._v(" "),a("hr"),e._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})])])}),[],!1,null,null,null);t.default=r.exports}}]);