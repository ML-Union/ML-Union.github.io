(window.webpackJsonp=window.webpackJsonp||[]).push([[80],{581:function(t,s,a){"use strict";a.r(s);var m=a(6),i=Object(m.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"请简述阿里妈妈提出的ls-plm模型的原理与数学形式。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#请简述阿里妈妈提出的ls-plm模型的原理与数学形式。"}},[t._v("#")]),t._v(" 请简述阿里妈妈提出的LS-PLM模型的原理与数学形式。")]),t._v(" "),a("p",[t._v("LS-PLM可以看作对逻辑回归的自然推广，在逻辑回归的基础上采用分而治之的思路，先对全量样本进行聚类分片，再对每个分类施以逻辑回归模型进行CTR预估。")]),t._v(" "),a("p",[t._v("其数学形式如下，首先用聚类函数"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"3C0"}})],1)],1)],1),t._v("(softmax多分类)对样本进行分类,在用LR模型计算分片中具体的CTR,两者相乘：")],1),t._v(" "),a("p"),a("p",[a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML",display:"true"}},[a("mjx-math",{staticClass:" MJX-TEX",attrs:{display:"true"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"f"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-munderover",{attrs:{space:"4"}},[a("mjx-over",{staticStyle:{"padding-bottom":"0.192em","padding-left":"0.412em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1)],1)],1),a("mjx-box",[a("mjx-munder",[a("mjx-row",[a("mjx-base",[a("mjx-mo",{staticClass:"mjx-lop"},[a("mjx-c",{attrs:{c:"2211"}})],1)],1)],1),a("mjx-row",[a("mjx-under",{staticStyle:{"padding-top":"0.167em","padding-left":"0.148em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-msub",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"3C0"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"3B7"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-munderover",{attrs:{space:"4"}},[a("mjx-over",{staticStyle:{"padding-bottom":"0.192em","padding-left":"0.412em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"m"}})],1)],1),a("mjx-box",[a("mjx-munder",[a("mjx-row",[a("mjx-base",[a("mjx-mo",{staticClass:"mjx-lop"},[a("mjx-c",{attrs:{c:"2211"}})],1)],1)],1),a("mjx-row",[a("mjx-under",{staticStyle:{"padding-top":"0.167em","padding-left":"0.148em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"i"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1)],1),a("mjx-mfrac",{attrs:{space:"2"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-msup",[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"3BC"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"B7"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1)],1)],1)],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-mrow",[a("mjx-munderover",{attrs:{limits:"false"}},[a("mjx-mo",{staticClass:"mjx-sop"},[a("mjx-c",{attrs:{c:"2211"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.285em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-spacer",{staticStyle:{"margin-top":"0.284em"}}),a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"j"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1),a("mjx-msup",{attrs:{space:"2"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"3BC"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"j"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"B7"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"B7"}})],1),a("mjx-mfrac",{attrs:{space:"3"}},[a("mjx-frac",{attrs:{type:"d"}},[a("mjx-num",[a("mjx-nstrut",{attrs:{type:"d"}}),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1),a("mjx-dbox",[a("mjx-dtable",[a("mjx-line",{attrs:{type:"d"}}),a("mjx-row",[a("mjx-den",[a("mjx-dstrut",{attrs:{type:"d"}}),a("mjx-mrow",[a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-msup",{attrs:{space:"3"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"2212"}})],1),a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"w"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"i"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"B7"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"x"}})],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1)],1),a("p"),t._v(" "),a("p",[t._v("论文中一个直观的例子，如下图，LR不能拟合非线性数据，MLR可以拟合非线性数据，因为划分-训练模式。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtiorlqt4nj60go04mgmr02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("这种菱形分界面（非线性数据）其实非常难学，但MLR在其中表现出色。通过控制分片数量m，可以平衡模型的拟合能力和过拟合。上图m=4。论文中m=12得到了不错的效果。")]),t._v(" "),a("p",[t._v("其中超参数即分片数"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1)],1)],1),t._v("可以很好地平衡模型的拟合与推广能力，当"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"m"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"="}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1),t._v("时，LS-PLM就退化为普通的逻辑回归。增大m可以带来无限制的非线性拟合能力。但与此同时，会增加计算、存储的开销，同时会带来过拟合的风险。具体如何选取m要结合实际情况取舍；")],1),t._v(" "),a("h2",{attrs:{id:"请简述ls-plm的结构化先验是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#请简述ls-plm的结构化先验是什么"}},[t._v("#")]),t._v(" 请简述LS-PLM的结构化先验是什么？")]),t._v(" "),a("p",[t._v("MLR中非常重要的就是如何划分原始特征空间。")]),t._v(" "),a("p",[t._v("通过引入结构化先验，我们使用用户特征来划分特征空间，使用广告特征来进行基分类器的训练，减小了模型的探索空间，收敛更容易。")]),t._v(" "),a("p",[t._v("同时，这也是符合我们认知的：不同的人群具有聚类特性，同一类人群具有类似的广告点击偏好。")]),t._v(" "),a("h2",{attrs:{id:"ls-plm中使用了线性偏置-是怎么回事"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm中使用了线性偏置-是怎么回事"}},[t._v("#")]),t._v(" LS-PLM中使用了线性偏置，是怎么回事？")]),t._v(" "),a("p",[t._v("针对CTR预估问题中存在的两种偏置：")]),t._v(" "),a("ul",[a("li",[t._v("Position Bias：排名第1位和第5位的样本，点击率天然存在差异。宝贝展示的页面、位置影响点击率")]),t._v(" "),a("li",[t._v("Sample Bias：PC和Mobile上的样本，点击率天然存在差异。")])]),t._v(" "),a("p",[t._v("在原来宝贝特征x的基础上，增加偏移向量y(场景、页数、位置等)。如果直接学习联合概率P(X,Y)面临问题：学习联合概率一定需要x和y的大部分组合，但是实际情况，并不是所有的x，y的组合都能有采样。针对这个问题，提出了带偏移MLR算法，形式化表述如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtip4jl8xxj60go075jro02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("而且，大规模非线性CTR预估和偏移变量的分解一起优化。并且，只需要很少的一些x，y组合就可以了。从论文给出的数据中，AUC提高了2-8个百分点。")]),t._v(" "),a("h2",{attrs:{id:"ls-plm是如何使用模型级联来训练的"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm是如何使用模型级联来训练的"}},[t._v("#")]),t._v(" LS-PLM是如何使用模型级联来训练的？")]),t._v(" "),a("p",[t._v("LS-PLM支持与LR的级联式训练。有点类似于Wide & Deep，一些强Feature配置成级联形式能够提高模型的收敛性。例如典型的应用方法是：以统计反馈类特征构建第一层模型，输出FBctr级联到第二级大规模稀疏ID特征中去，能得到更好的提升效果。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtip5ipj89j60go0jcgm102.jpg",alt:""}})]),t._v(" "),a("p",[t._v("反馈特征常用的如反馈CTR，是指系统上线一段时间之后得到的历史CTR值。")]),t._v(" "),a("h2",{attrs:{id:"ls-plm模型的优势有哪些"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm模型的优势有哪些"}},[t._v("#")]),t._v(" LS-PLM模型的优势有哪些？")]),t._v(" "),a("p",[t._v("LS-PLM适用于推荐广告等大规模稀疏数据的场景，其优势在于：")]),t._v(" "),a("p",[t._v("1）端到端的非线性学习能力：LS-PLM具有样本分片的能力，因此能够挖掘出非线性模式，省去了大量的人工样本处理和特征工程的过程，可以端到端训练，便于用一个全局模型对不同应用领域、业务场景进行统一建模。")]),t._v(" "),a("p",[t._v("2）模型的稀疏性强：在建模时引入了L1和L2,1范数，可使得最终训练出来的模型局哟偶高度的稀疏度，使模型的部署更加轻量级。模型服务过程仅需使用权重非零特征，因此稀疏模型也使其在线推断效率更高。")]),t._v(" "),a("h2",{attrs:{id:"ls-plm模型为何要进行增量训练"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm模型为何要进行增量训练"}},[t._v("#")]),t._v(" LS-PLM模型为何要进行增量训练？")]),t._v(" "),a("p",[t._v("实验证明，MLR利用结构先验（用户特征进行聚类，广告特征进行分类）进行pretrain，然后再增量进行全空间参数寻优训练，会使得收敛步数更少，收敛更稳定。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtip9f7by5j60go0adaa802.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"ls-plm的工程中使用了并行化-请介绍一下。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm的工程中使用了并行化-请介绍一下。"}},[t._v("#")]),t._v(" LS-PLM的工程中使用了并行化，请介绍一下。")]),t._v(" "),a("p",[t._v("论文里的实现基于分布式，包括两个维度的并行化，模型并行化，数据并行化。每一个计算节点中都包含两种角色：Server Node, Worker Node，这样做的好处有两点：")]),t._v(" "),a("ul",[a("li",[t._v("最大化利用CPU计算资源。之前大多数Server Node单独放到一台服务器上，造成CPU资源的极大浪费。")]),t._v(" "),a("li",[t._v("最大化利用Memory资源。")])]),t._v(" "),a("h2",{attrs:{id:"ls-plm模型工程化中有一个-common-feature-trick-请简述一下。"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm模型工程化中有一个-common-feature-trick-请简述一下。"}},[t._v("#")]),t._v(" LS-PLM模型工程化中有一个 Common Feature Trick，请简述一下。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtipc3rmqgj60go05jq2v02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("一个用户在一次pageview中会看到多个广告，每个广告都组成一条样本。所以这些样本之间很多特征都是重复的。这些特征包括：用户特征（年龄、性别等）、用户的历史访问信息（之前购买的物品、喜欢的店铺等）。那么我们对于向量内积的计算分成两部分：common和non-common parts:")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtipckry3mj60fk05eglk02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("利用Common Feature Trick可以从三个方面来优化并行化：")]),t._v(" "),a("ul",[a("li",[t._v("对于有Common Feature的样本作为一组一起训练，并保证在存储在一个worker上")]),t._v(" "),a("li",[t._v("对于Common Feature仅仅保存一次，以便来节省内存")]),t._v(" "),a("li",[t._v("对于Common Feature的loss和梯度更新只需要一次即可")])]),t._v(" "),a("p",[t._v("下面是实验结果，可以看到Common Feature Trick效果还是非常明显的。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtipd3ol9uj60go02wq2x02.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"ls-plm模型与深度学习模型有什么联系"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ls-plm模型与深度学习模型有什么联系"}},[t._v("#")]),t._v(" LS-PLM模型与深度学习模型有什么联系？")]),t._v(" "),a("p",[t._v("LS-PLM可以看做是一个加入了注意力（Attention）机制的三层神经网络模型，其中输入层是样本的特征向量，中间层是由m个神经元组成的隐层，其中m是分片的个数，输出层为单一的神经元；在隐层与输出层之间，神经元之间的权重是由分片函数得出的注意力得分来确定的，即样本属于某个分片的概率就是其注意力得分。")]),t._v(" "),a("hr"),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})])])}),[],!1,null,null,null);s.default=i.exports}}]);