(window.webpackJsonp=window.webpackJsonp||[]).push([[82],{580:function(t,s,a){"use strict";a.r(s);var m=a(6),i=Object(m.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"dien引入序列信息的动机是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dien引入序列信息的动机是什么"}},[t._v("#")]),t._v(" DIEN引入序列信息的动机是什么？")]),t._v(" "),a("p",[t._v("在电商平台中，用户行为是兴趣的载体，且是以时间而产生的序列数据，其间存在的依赖、次序隐藏着用户喜好。")]),t._v(" "),a("p",[t._v("当前时刻的兴趣直接导致了下一行为的产生。因此设计了DIN模型将用户的历史行为来表示用户的兴趣，通过attention来捕获和目标物品相关的兴趣。")]),t._v(" "),a("p",[t._v("但是在电商推荐的场景下，可以观察到用户的兴趣是不断变化的。例如用户对衣服的喜好，会随季节、时尚风潮以及个人品味的变化而变化，呈现一种连续的变迁趋势。这说明用户的兴趣是不断进化的，而DIN抽取的用户兴趣之间是独立无关联的，没有捕获到兴趣的动态进化性，这是需要解决的第一个问题。")]),t._v(" "),a("p",[t._v("其次在淘宝平台中，用户的兴趣是丰富多样的，且每个兴趣的演变基本互不影响。此外，影响最终行为的仅仅是与目标商品相关的兴趣。所以DIEN仍然采用了attention机制，捕获与目标商品相关商品的兴趣发展路径。")]),t._v(" "),a("p",[t._v("DIEN最大的特点是不但要找到用户的interest，还要抓住用户interest的进化过程。作者们将GRU融合到网络中，从而捕获到变化的sequence。")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("DIEN关注电商场景中兴趣演化的过程，并提出了新的网络结构来建模兴趣进化的过程，这个模型能够更精确的表达用户兴趣，同时带来更高的CTR预估准确率。")])]),t._v(" "),a("li",[a("p",[t._v("设计了兴趣抽取层，并通过计算一个辅助loss，来提升兴趣表达的准确性。")])]),t._v(" "),a("li",[a("p",[t._v("设计了兴趣进化层，来更加准确的表达用户兴趣的动态变化性。")])])]),t._v(" "),a("h2",{attrs:{id:"请大概叙述一下dien的整体结构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#请大概叙述一下dien的整体结构"}},[t._v("#")]),t._v(" 请大概叙述一下DIEN的整体结构？")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm31e41ruj61540k476x02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("新模型较之于DIN模型，其他部分保持一致，变化只在于用户行为序列（UBS）的处理做了调整，将其组织成了序列数据的形式。这里包含了3个部分，最底层是Behavior Layer，用于将用户浏览过的商品转换成对应的embedding，并且按照浏览时间做排序，中间层是兴趣提取层Interest Extractor Layer，最上层是兴趣发展层Interest Evolving Layer。")]),t._v(" "),a("h2",{attrs:{id:"请说一下dien中兴趣抽取层的构造"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#请说一下dien中兴趣抽取层的构造"}},[t._v("#")]),t._v(" 请说一下DIEN中兴趣抽取层的构造？")]),t._v(" "),a("p",[t._v("如上图中黄色区域所示，兴趣抽取层Interest Extractor Layer的主要目标是从embedding数据中提取出interest。但一个用户在某一时间的interest不仅与当前的behavior有关，也与之前的behavior相关，所以作者们使用GRU单元来提取interest，GRU输出h(t)如下所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm3iegilaj614w09wgmn02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("这里可以认为"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("是提取出的用户的初步兴趣表示，为了更好地表达用户的兴趣，作者还为兴趣抽取层引入了一个有监督学习：输入是按照时间步排列的商品embedding向量，假设第"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1),t._v("个时间步输入"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，GRU输出隐单元"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，令下一个时间步的输入向量"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("作为正样本，随机采样负样本"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，且"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mn",{staticClass:"mjx-n",attrs:{space:"3"}},[a("mjx-c",{attrs:{c:"1"}})],1),a("mjx-msup",[a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"0.363em"}},[a("mjx-mo",{staticClass:"mjx-n",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"2032"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"2260"}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("，"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v("与正负样本向量分别做内积，得到预测结果，并引入一个辅助的logloss：")],1),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm3nqmjccj60fo0ai0tg02.jpg",alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm3qvum4fj60ra056aa902.jpg",alt:""}})]),t._v(" "),a("p",[t._v("L_target是CTR任务的logloss函数，将CTR的loss和辅助loss相加定义为整个网络的loss进行优化。α是超参数来平衡两个loss的权重。这里辅助loss有几个好处，当GRU处理较长序列的时候有助于降低反向传播的难度，对于商品embedding的学习也有助益。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm3xabsdcj610002qq2x02.jpg",alt:""}})]),t._v(" "),a("h2",{attrs:{id:"请说一下dien中兴趣进化层的构造"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#请说一下dien中兴趣进化层的构造"}},[t._v("#")]),t._v(" 请说一下DIEN中兴趣进化层的构造？")]),t._v(" "),a("p",[t._v("有了用户的兴趣表示，Evolution Layer的主要目标就是去刻画用户兴趣的演变过程（观测到兴趣随环境和认知的变化而变化）。因此作者设计了AUGRU结构，用attention机制来局部激活与目标商品相关的局部兴趣，并对存在于这些兴趣之间的依赖建模，捕捉兴趣的演变过程。")]),t._v(" "),a("p",[t._v("具体如模型中红色区域所示，这里使用了第2个GRU。将目标商品的embedding向量与第1个GRU的输出隐向量发生交互，生成attention score，计算公式如下所示：其中，hₜ 是隐向量，e是目标商品的嵌入向量，W是需要训练的参数矩阵。最后用softmax对attention score进行归一化。")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm49y9zmwj60ap02gaa402.jpg",alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm4bldodgj60ij06kgls02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("对于如何结合attention和GRU，文中介绍了三种方式：")]),t._v(" "),a("p",[t._v("1、GRU with attentional input (AIGRU) 用attention直接影响这一层的输入。\n"),a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm4f5ulu4j604x01b3ya02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("2、Attention based GRU(AGRU) 用 aₜ 代替GRU的update gate输出：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm4gqr4rmj609a018glh02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("3、GRU with attentional update gate (AUGRU) 用 aₜ 影响GRU的update gate输出（保留每个维度的影响）：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtm4hzqsnrj609s0210so02.jpg",alt:""}})]),t._v(" "),a("p",[t._v("从上面的公式中可以看出，AIGRU 激活局部兴趣和捕获兴趣演变的过程是相互独立的。仅仅是用attention来影响GRU的输入，且即便输入为 0（无关的兴趣）也还是会对hidden state产生影响；")]),t._v(" "),a("p",[t._v("AGRU用 aₜ 替代 GRU 的 update gate，直接控制 hidden state 的更新，将 attention 机制融入到了捕获兴趣演变的过程中，一定程度上弥补了 AIGRU 的不足。")]),t._v(" "),a("p",[t._v("但是，原先 GRU 中控制 hidden state 更新的是一个包含多个维度的向量，AGRU 用纯量替代略有不妥，因此这篇文章设计了 AUGRU，用 aₜ 影响 uₜ ，以间接作用于 hidden state的更新。")]),t._v(" "),a("h2",{attrs:{id:"dien为什么要引入辅助loss-它的好处是什么"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#dien为什么要引入辅助loss-它的好处是什么"}},[t._v("#")]),t._v(" DIEN为什么要引入辅助loss？它的好处是什么？")]),t._v(" "),a("p",[t._v("GRU只能学习行为之间的依赖，并不能很好反映用户兴趣。 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"L"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"a"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"r"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"g"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"e"}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1)],1)],1),t._v("只包含了最终兴趣的监督信息（因为最终兴趣导致了点击行为），而中间的历史状态 "),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"("}})],1),a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"<"}})],1),a("mjx-mi",{staticClass:"mjx-i",attrs:{space:"4"}},[a("mjx-c",{attrs:{c:"T"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:")"}})],1)],1)],1),t._v(" 并不能得到监督信息来指导学习。我们知道兴趣可能会导致产生多个连续行为。所以模型引入辅助loss。具体来说就是用行为"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"b"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-TeXAtom",{attrs:{size:"s"}},[a("mjx-mi",{staticClass:"mjx-i"},[a("mjx-c",{attrs:{c:"t"}})],1),a("mjx-mo",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"+"}})],1),a("mjx-mn",{staticClass:"mjx-n"},[a("mjx-c",{attrs:{c:"1"}})],1)],1)],1)],1)],1)],1),t._v("来指导"),a("mjx-container",{staticClass:"MathJax",attrs:{jax:"CHTML"}},[a("mjx-math",{staticClass:" MJX-TEX"},[a("mjx-msub",[a("mjx-mi",{staticClass:"mjx-i",attrs:{noIC:"true"}},[a("mjx-c",{attrs:{c:"h"}})],1),a("mjx-script",{staticStyle:{"vertical-align":"-0.15em"}},[a("mjx-mi",{staticClass:"mjx-i",attrs:{size:"s"}},[a("mjx-c",{attrs:{c:"t"}})],1)],1)],1)],1)],1),t._v("的学习，正样本就是真实的下一个item，负样本就是从item set中随机抽取的item。")],1),t._v(" "),a("p",[t._v("辅助loss的引入有多个好处：")]),t._v(" "),a("p",[t._v("1、正如作者强调的，辅助loss可以帮助GRU的隐状态更好地表示用户兴趣。")]),t._v(" "),a("p",[t._v("2、RNN在长序列建模场景下梯度传播可能并不能很好的影响到序列开始部分，如果在序列的每个部分都引入一个辅助的监督信号，则可一定程度降低优化难度。")]),t._v(" "),a("p",[t._v("3、辅助loss可以给embedding层的学习带来更多语义信息，学习到item对应的更好的embedding。")]),t._v(" "),a("hr"),t._v(" "),a("p",[a("img",{attrs:{src:"https://tva1.sinaimg.cn/large/008i3skNly1gtqjt0a9rnj61ou0pwaci02.jpg",alt:""}})])])}),[],!1,null,null,null);s.default=i.exports}}]);